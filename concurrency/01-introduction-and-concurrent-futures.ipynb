{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Erudio logo](../img/erudio-logo-small.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Programming Concurrency in Python\n",
    "\n",
    "This module aims at an intermediate Python programmer.  We look at several models and paradigms for writing concurrent programs using tools in the Python standard library.  \n",
    "\n",
    "The course addresses several pitfalls developers face with concurrency, including race conditions and deadlocks.  As well, it explains the pros and cons of working with threads versus processes as concurrency models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What will be covered in this course\n",
    "\n",
    "* High-level abstraction `concurrent.futures`.\n",
    "* Basics of threading, using `threading`.\n",
    "* Sharing data among threads and race conditions.\n",
    "* Locks, deadlocks, and circular dependencies.\n",
    "* The Python Global Interpreter Lock.\n",
    "* Process parallelism with `multiprocessing`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# 1.1 Concurrent.futures\n",
    "\n",
    "In this lesson, we jump immediately to the highest-level abstraction for concurrency that the Python standard library provides: the `concurrent.futures` module.  \n",
    "\n",
    "Some of the terms presented here may not be entirely familiar yet, but I believe you can understand them in context."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "**Most** of the time, when you write concurrent programs in Python, you should use `concurrent.futures`.  \n",
    "\n",
    "The module provides a beautiful and Pythonic interface that makes concurrency easy, while hiding most of the messy details of threads, processes, locks, deadlocks, race conditions, data sharing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "...Of course, most of the time is not **all** of the time.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "You will sometimes need to reach down to lower-level interfaces provided by other modules that `concurrent.futures` is built on top of.  Those building blocks make up the remaining lessons of this course.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "It might be wise to return to this lesson at the end, after you have completed the other lessons."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Parallel and Sequential\n",
    "\n",
    "The problems that `concurrent.futures` best addresses are ones that are *embarrassingly parallel* (or nearly so).  If you can express your problems as a large number of \"tasks\" each of which is already bundled with the data it needs, concurrency is easiest.  \n",
    "\n",
    "On the other hand, if every task depends on the result of its predecessor, a program is *strictly sequential*.  Many real computations are somewhere in the middle."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Example: Embarrassingly Parallel\n",
    "\n",
    "Problems that are embarrassingly parallel include Monte Carlo simulations, web scraping or distributed data acquisition, many types of graphic rendering (with pixels independent), and other domains.\n",
    "\n",
    "A diagram of such tasks might look like this (an arrow indicates one task depends on the output of another task).\n",
    "\n",
    "<img src=\"../img/embarrasingly-parallel.png\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Example: Strictly Sequential\n",
    "\n",
    "Other problems are sequential by nature, and cannot be made concurrent in any meaningful way.  \n",
    "\n",
    "For example, most pseudo-random number generators keep internal state, and perform a complex mathematical modification of that state each time they move to the next state (typically not reversibly, but that is inessential here).\n",
    "\n",
    "<img src=\"../img/strictly-sequential.png\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Example: Mixed Data Flow\n",
    "\n",
    "Many problems fall between these two pictures.  Some tasks have sequential dependencies, but others are independent.  \n",
    "\n",
    "For example, perhaps you have to aggregate and process per-second data sequentially for a day, but then you need to reaggregate daily data into decades in a s similar way.  Some things can be concurrent, but others are dependencies.\n",
    "\n",
    "<img src=\"../img/mixed-data-flow.png\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Let us load the various modules and names we use in this lesson."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install ipywidgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "#----- Concurrency facilities\n",
    "from concurrent.futures import (\n",
    "    ThreadPoolExecutor, ProcessPoolExecutor, TimeoutError, as_completed)\n",
    "from multiprocessing import cpu_count\n",
    "from threading import current_thread, Thread\n",
    "from queue import Queue\n",
    "#----- General utilities\n",
    "from datetime import datetime, timedelta\n",
    "import requests\n",
    "from pprint import pprint\n",
    "from time import sleep, perf_counter\n",
    "from collections import namedtuple\n",
    "from random import sample\n",
    "#----- Some pretty display later\n",
    "from ipywidgets import IntProgress, Layout, Label\n",
    "from IPython.display import display\n",
    "from random import random\n",
    "from multiprocessing.pool import ThreadPool\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Executors\n",
    "\n",
    "Executors are the main construct in `concurrent.futures`. They are similar to `multiprocessing.Pool`, which we look at in a later lesson. Once an executor has been instantiated, we can `submit` jobs, or even `map` tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "In the module are two executors: `ThreadPoolExecutor` and `ProcessPoolExecutor`. They have the same interface, but use different concurrency mechanisms.  The trade-offs of processes and threads are discussed in later lessons."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "We need to define a task to perform, using a Python callable. In this example, we'll use multithreading to run two functions in parallel. Multithreading improves program performance by allowing multiple tasks to run simultaneously. It creates two separate threads, each executing a function, and shows how to coordinate the execution of these threads to work together effectively.\n",
    "\n",
    "For this lesson, we use a server that reports hisorical cryptocurrency prices on different markets.  The server takes about a second to return a response to each query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "def task(id):\n",
    "    print(f'Starting the task {id}...')\n",
    "    sleep(1)\n",
    "    return f'Done with task {id}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting the task 1...\n",
      "Done with task 1\n",
      "Starting the task 2...\n",
      "Done with task 2\n",
      "It took 1.9959884000018064 second(s) to finish.\n",
      "CPU times: total: 15.6 ms\n",
      "Wall time: 2.01 s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "start = perf_counter()\n",
    "\n",
    "print(task(1))\n",
    "print(task(2))\n",
    "\n",
    "finish = perf_counter()\n",
    "\n",
    "print(f\"It took {finish-start} second(s) to finish.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "We can call the function, with given arguments by wrapping it in an executor.  There is no advantage in doing so for a single function call, but it is a starting point.\n",
    "We are going to use `ThreadPoolExecutor`. The ThreadPoolExecutor class extends the Executor class and returns a Future object.\n",
    "\n",
    "### Executor\n",
    "The Executor class has three methods to control the thread pool:\n",
    "\n",
    "    submit() – dispatch a function to be executed and return a Future object. The submit() method takes a function and executes it asynchronously.\n",
    "    map() – execute a function asynchronously for each element in an iterable.\n",
    "    shutdown() – shut down the executor.\n",
    "\n",
    "When you create a new instance of the ThreadPoolExecutor class, Python starts the Executor.\n",
    "\n",
    "Once completing working with the executor, you must explicitly call the shutdown() method to release the resource held by the executor. To avoid calling the shutdown() method explicitly, you can use the context manager."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using the submit() method example\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting the task 1...\n",
      "Starting the task 2...\n",
      "Done with task 1\n",
      "Done with task 2\n",
      "It took 1.0266852999993716 second(s) to finish.\n"
     ]
    }
   ],
   "source": [
    "start = perf_counter()\n",
    "\n",
    "with ThreadPoolExecutor() as executor:\n",
    "    f1 = executor.submit(task, 1)\n",
    "    f2 = executor.submit(task, 2)\n",
    "\n",
    "    print(f1.result())\n",
    "    print(f2.result())    \n",
    "\n",
    "finish = perf_counter()\n",
    "\n",
    "print(f\"It took {finish-start} second(s) to finish.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Executor .map()\n",
    "\n",
    "The submit() method returns a Future object. In this example, we have two Future objects f1 and f2. To get the result from the Future object, we called its result() method.\n",
    "\n",
    "While you can perfectly well call `.submit()` manually to create many futures, very often it is easier and more clear to create an entire family of implicit futures for different data you wish to process concurrently.  \n",
    "\n",
    "When using `.map()` to create families of workers, you may only pass a single argument.  This simply means you have to package each *data value* into a collection like a tuple or dictionary that can be destructured within the worker function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting the task 1...\n",
      "Starting the task 2...\n",
      "Done with task 1\n",
      "Done with task 2\n",
      "It took 1.0076016999992135 second(s) to finish.\n"
     ]
    }
   ],
   "source": [
    "start = perf_counter()\n",
    "\n",
    "with ThreadPoolExecutor() as executor:\n",
    "    results = executor.map(task, [1,2])\n",
    "    for result in results:\n",
    "        print(result)\n",
    "\n",
    "finish = perf_counter()\n",
    "\n",
    "print(f\"It took {finish-start} second(s) to finish.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Another Practical Example\n",
    "We'll utilise the urllib package available to download 5 images parallely"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python_Regius.jpg was downloaded...\n",
      "Python_bivittatus_1701.jpg was downloaded...\n",
      "Dulip_Wilpattu_Python1.jpg was downloaded...\n",
      "Rock_python_pratik.JPG was downloaded...\n",
      "Baby_carpet_python_caudal_luring.jpg was downloaded...\n",
      "It took 1.9715921999995771 second(s) to finish.\n"
     ]
    }
   ],
   "source": [
    "from concurrent.futures import ThreadPoolExecutor\n",
    "from urllib.request import urlopen\n",
    "import time\n",
    "import os\n",
    "\n",
    "def download_image(url):\n",
    "    image_data = None\n",
    "    with urlopen(url) as f:\n",
    "        image_data = f.read()\n",
    "\n",
    "    if not image_data:\n",
    "        raise Exception(f\"Error: could not download the image from {url}\")\n",
    "\n",
    "    filename = os.path.basename(url)\n",
    "    with open(filename, 'wb') as image_file:\n",
    "        image_file.write(image_data)\n",
    "        print(f'{filename} was downloaded...')\n",
    "\n",
    "start = time.perf_counter()\n",
    "\n",
    "urls = ['https://upload.wikimedia.org/wikipedia/commons/9/9d/Python_bivittatus_1701.jpg',\n",
    "        'https://upload.wikimedia.org/wikipedia/commons/4/48/Python_Regius.jpg',\n",
    "        'https://upload.wikimedia.org/wikipedia/commons/d/d3/Baby_carpet_python_caudal_luring.jpg',\n",
    "        'https://upload.wikimedia.org/wikipedia/commons/f/f0/Rock_python_pratik.JPG',\n",
    "        'https://upload.wikimedia.org/wikipedia/commons/0/07/Dulip_Wilpattu_Python1.jpg']\n",
    "\n",
    "with ThreadPoolExecutor() as executor:\n",
    "      executor.map(download_image, urls)\n",
    "\n",
    "finish = time.perf_counter()    \n",
    "\n",
    "print(f'It took {finish-start} second(s) to finish.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Futures\n",
    "\n",
    "In the examples above, the `submit` method immediately returns a `Future` object. These objects are an abstraction of a task that is being processed. \n",
    "\n",
    "They have multiple useful methods; the most important is `.result(timeout=None)`. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "The `timeout` argument lets us wait a finite number of seconds until a result is produced. If no result is generated in that time, a `TimeoutError` is raised."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TimeoutError()\n",
      "Python_bivittatus_1701.jpg was downloaded...\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    ex = ThreadPoolExecutor()\n",
    "    future = ex.submit(download_image, urls[0])\n",
    "    data = future.result(timeout=0.5)\n",
    "except TimeoutError as err:\n",
    "    pprint(err)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Another important method of a `Future` is `.done()`.  Notice that we might submit multiple tasks, and each might become \"done\" afer different durations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Just submitted: done? False\n",
      "Python_Regius.jpg was downloaded...\n",
      "Python_bivittatus_1701.jpg was downloaded...\n",
      "Slept a while: done? True\n",
      "Image downloaded from URL 1: $None\n",
      "Image downloaded from URL 2: $None\n",
      "Waited on result: done? True\n"
     ]
    }
   ],
   "source": [
    "with ThreadPoolExecutor() as ex:\n",
    "    future1 = ex.submit(download_image, urls[0])\n",
    "    future2 = ex.submit(download_image, urls[1])\n",
    "    print(\"Just submitted: done?\", future1.done())\n",
    "    sleep(3)\n",
    "    print(\"Slept a while: done?\", future1.done())\n",
    "    print(f\"Image downloaded from URL 1: ${future1.result()}\")\n",
    "    print(f\"Image downloaded from URL 2: ${future2.result()}\")\n",
    "    print(\"Waited on result: done?\", future1.done())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Executor .map()\n",
    "\n",
    "While you can perfectly well call `.submit()` manually to create many futures, very often it is easier and more clear to create an entire family of implicit futures for different data you wish to process concurrently.  \n",
    "\n",
    "When using `.map()` to create families of workers, you may only pass a single argument.  This simply means you have to package each *data value* into a collection like a tuple or dictionary that can be destructured within the worker function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "When you call `.map()` it is as if you called `.result()` on each future, although the futures are not named."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Futures as_completed()\n",
    "\n",
    "The `.map()` method is very concise for mapping one function to multiple data sets it should process.  It *did* require us to refactor the function to unpack a single *data* object.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "A bit more flexible is using the function `as_completed()` to iterate over results as they become available.  This will block on the next result becoming available, but the threads or processes generating those results will keep running while your code handles an available one.\n",
    "\n",
    "We'll create a another function task that returns a value  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# custom task that will sleep for a variable amount of time\n",
    "def task(name):\n",
    "    value = random()\n",
    "    sleep(value * 10)\n",
    "    return f'Task={name}: {value:.2f}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task=8: 0.14\n",
      "Task=3: 0.22\n",
      "Task=4: 0.26\n",
      "Task=5: 0.39\n",
      "Task=2: 0.43\n",
      "Task=6: 0.72\n",
      "Task=7: 0.93\n",
      "Task=0: 0.97\n",
      "Task=1: 0.97\n",
      "Task=9: 0.99\n"
     ]
    }
   ],
   "source": [
    "with ThreadPoolExecutor(10) as executor:\n",
    "    # submit tasks and collect futures\n",
    "    futures = [executor.submit(task, i) for i in range(10)]\n",
    "    # process task results as they are available\n",
    "    for future in as_completed(futures):\n",
    "        # retrieve the result\n",
    "        result = future.result()\n",
    "        print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Producer/Consumer Pattern\n",
    "\n",
    "What we did so far supposed that we knew the data associated with our overall processing in advance of launching workers.  That will not always be the case; in particular, some workers may generate the data for other workers to process."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "The trick to allowing this setup is the use of **queues** (or a similar data structure) that allow safe concurrent access.  A queue allows one worker to push data into a collection, and another worker to pop data, without risking one overwriting the other or other data integrity problems."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "We will extend the example of querying prices from exchanges, but with the addition of a **producer** that generates requests at the same time as other **consumers** are processing them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "The architecture of this example is a bit more detailed, to resemble real programs you will write.  We will launch three types of workers as part of this overall system.\n",
    "\n",
    "* A **monitor** that will simply show the evolving queues\n",
    "* A **producer** that will feed requests into the TODO queue\n",
    "* Multiple **consumers** that will act on requests, and add to the RESULTS queue\n",
    "\n",
    "Let us first create the queues that the tasks will work with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "Q_todo, Q_results, Q_info = Queue(), SimpleQueue(), SimpleQueue()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "While it might be more robust to put the initial introspection of the server into a concurrent task, here we simplify slightly and perform this small task in a non-concurrent way first. In this example, we will define a simple producer task that generates a random number between 1 and 10, blocks for that few seconds, then places the generated value on the shared queue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# producer task\n",
    "def producer_task(queue):\n",
    "    # generate a random number between 0 and 10\n",
    "    value = random() * 10\n",
    "    # block for a moment to simulate work\n",
    "    sleep(value)\n",
    "    # push data into queue\n",
    "    queue.put(value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Next let us define the monitor that reports progress. This uses some magic with IPython widgets that are not the subject of this lesson; do not worry about those."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "def monitor(Q_todo, Q_results, Q_info):\n",
    "    # Create the visual monitor widgets\n",
    "    todo = IntProgress(value=0, min=0, max=nreqs, step=1, description='TODO', \n",
    "                orientation='horizontal', bar_style='info', layout=Layout(width='50%'))\n",
    "    done = IntProgress(value=0, min=0, max=nreqs, step=1, description='DONE', \n",
    "                orientation='horizontal', bar_style='success', layout=Layout(width='50%'))\n",
    "    info = Label(value='STARTING...')\n",
    "    display(todo); display(done); display(info)\n",
    "    \n",
    "    while True:\n",
    "        todo.value = Q_todo.qsize()\n",
    "        done.value = Q_results.qsize()\n",
    "        try:\n",
    "            info.value = f\"{Q_info.get(timeout=3)}\"\n",
    "        except Empty:\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "We will mow define a thread pool with 10 workers and issue 10 producers into the pool to complete as fast as they are able. We need to create a producer function that will feed queries into the TODO queue.  In this case, the data involved is a small tuple of query elements; in other cases, the data itself might be substantial (such as a numeric array or a large text).  This producer artificially limits the rate at which it adds to the queue just to simulate real-world applications."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# producer manager task\n",
    "def producer_manager(queue):\n",
    "    with ThreadPool(10) as pool:\n",
    "        # use threads to generate items and put into the queue\n",
    "        _ = [pool.apply_async(producer_task, args=(queue,)) for _ in range(20)]\n",
    "        # wait for all tasks to complete\n",
    "        pool.close()\n",
    "        pool.join()\n",
    "    # put a signal to expect no further tasks\n",
    "    queue.put(None)\n",
    "    print('>producer_manager done.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "The consumer task will run in a loop until explicitly stopped.\n",
    "\n",
    "In each iteration, the consumer task will retrieve an item from the shared queue. If the item is a message that indicates no further work, it will re-add the message to the queue for other consumers to process and exit. Otherwise, it will retrieve the value, block for that number of seconds to simulate work, and repeat the process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# consumer task\n",
    "def consumer_task(queue):\n",
    "    # run until there is no more work\n",
    "    while True:\n",
    "        # retrieve one item from the queue\n",
    "        value = queue.get()\n",
    "        # check for signal of no more work\n",
    "        if not value:\n",
    "            # put back on the queue for other consumers\n",
    "            queue.put(value)\n",
    "            # shutdown\n",
    "            return\n",
    "        # block for a moment to simulate work\n",
    "        sleep(value)\n",
    "        print(f'Consumer got: {value}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "The consumer manager will create and manage a pool of 5 consumer tasks which will run for as long as there is work on the shared queue to complete. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# consumer manager\n",
    "def consumer_manager(queue):\n",
    "    # create thread pool\n",
    "    with ThreadPool(5) as pool:\n",
    "        # start consumer tasks\n",
    "        _ = [pool.apply_async(consumer_task, args=(queue,)) for _ in range(5)]\n",
    "        pool.close()\n",
    "        pool.join()\n",
    "    print('>consumer_manager done.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, the main process will start a separate thread for each of the producer and consumer managers and wait for all work to be completed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Consumer got: 1.494394968076238\n",
      "Consumer got: 2.428691892073779\n",
      "Consumer got: 2.4623583161935345\n",
      "Consumer got: 2.7045256117771235\n",
      "Consumer got: 3.1714995645144684\n",
      "Consumer got: 4.146393961968611\n",
      ">producer_manager done.\n",
      "Consumer got: 4.695807546849725\n",
      "Consumer got: 5.008894425015034\n",
      "Consumer got: 5.250008310811001\n",
      "Consumer got: 5.9365590283533525\n",
      "Consumer got: 6.009300076329285\n",
      "Consumer got: 6.156578136946722\n",
      "Consumer got: 6.244832190579518\n",
      "Consumer got: 7.214463435925107\n",
      "Consumer got: 7.506665065591452\n",
      "Consumer got: 7.906552597376182\n",
      "Consumer got: 8.507827081841954\n",
      "Consumer got: 8.765992234212824\n",
      "Consumer got: 9.134922486960907\n",
      "Consumer got: 9.125252527802132\n",
      ">consumer_manager done.\n",
      ">main done.\n",
      "CPU times: total: 15.6 ms\n",
      "Wall time: 29.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "queue = Queue()\n",
    "# run the consumer\n",
    "consumer = Thread(target=consumer_manager, args=(queue,))\n",
    "consumer.start()\n",
    "# run the producer\n",
    "producer = Thread(target=producer_manager, args=(queue,))\n",
    "producer.start()\n",
    "# wait for the producer to finish\n",
    "producer.join()\n",
    "# wait for the consumer to finish\n",
    "consumer.join()\n",
    "# report a final message\n",
    "print('>main done.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Recap of the example\n",
    "Running the example first creates the shared queue. Next, the consumer manager thread is started. This in turn starts the consumer thread pool and all five consumer workers. The workers run and await items to appear on the shared queue.\n",
    "\n",
    "Next, a new thread is created and started for the producer manager. This starts a thread pool with 10 workers and issues 10 tasks to the pool, each producing one item onto the shared queue as fast as they are able.The main thread then waits for the threads to complete.\n",
    "\n",
    "Each producer task generates a random number, sleeps, and places the value on the shared queue before exiting. Consumers read a value from the shared queue, sleep, then report the message before repeating the process.\n",
    "\n",
    "All consumers finish and the producer manager places a signal to expect no further tasks on the shared queue, then shuts down. The consumer tasks continue to retrieve items from the queue until the shutdown message is read. Each consumer then shuts down in turn and finally, the consumer manager shuts down."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Summary\n",
    "\n",
    "The `concurrent.futures` module is the most abstract, highest-level concurrency module in the Python standard library. It **should be** your default option when writing concurrent code.  \n",
    "\n",
    "Only when you need more advanced capabilities, will you need to use the `threading` or `multiprocessing` modules directly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Description\n",
    "\n",
    "For this exercise you will parallelize a toy problem to show the pattern of `concurrent.futures` use.  For this task, a simple serial approach will be faster than thread creation overhead.  However, it is easy to imagine reading much larger files where disk I/O time was significant enough to change this balance.\n",
    "\n",
    "The code in the Setup generates 1000 files, each of which contains 20 integer, one per line.  You with read each file, and multiply together the numbers on lines 3 and 17 (one-based indexing of line-number).  In turn, you want the sum of all these multiplications as the return value of your function.\n",
    "\n",
    "For the task, use however many workers you think is most appropriate (pretending the files were much larger and the disk much slower).  The function `sum_of_products()` should return the computed answer, calculated in a multi-threaded manner.\n",
    "\n",
    "A hint when writing this.  Later lessons talk about race conditions, but just as advice, it is unsafe to put multiple partial results in a list from different threads.  However, doing so with a `collections.deque` is safe, and uses the same `.append()` method to add things."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from concurrent.futures import ThreadPoolExecutor\n",
    "from collections import deque\n",
    "\n",
    "from random import sample, seed, randint\n",
    "from string import ascii_letters\n",
    "from time import time\n",
    "\n",
    "def create_files(random_state=0):\n",
    "    seed(random_state)\n",
    "    for _files in range(1000):\n",
    "        name = \"\".join(sample(ascii_letters, 5))\n",
    "        with open(f\"tmp-{name}.numbers\", 'w') as fh:\n",
    "            for _lines in range(20):\n",
    "                print(randint(1, 99), file=fh)\n",
    "    return time()\n",
    "\n",
    "created = create_files()\n",
    "    \n",
    "def sum_of_products():\n",
    "    ThreadPoolExecutor  # Use this for something\n",
    "    return 2481234"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sum_of_products():\n",
    "    from glob import glob\n",
    "    def getsum(fname):\n",
    "        nums = [int(n) for n in open(fname)]\n",
    "        return nums[2] * nums[16]\n",
    "\n",
    "    with ThreadPoolExecutor(max_workers=64) as ex:\n",
    "        final = sum(ex.map(getsum, glob('tmp-*.numbers')))\n",
    "\n",
    "    return final"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_final():\n",
    "    assert sum_of_products() == 2483973, f\"Wrong total computed\"\n",
    "    \n",
    "test_final()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_files_touched():\n",
    "    import os\n",
    "    for id_ in \"uTHni AgwYn yiQnJ nlrgE wzXTs\".split():\n",
    "        assert os.stat(f\"tmp-{id_}.numbers\").st_atime > created, \\\n",
    "                \"Files not read after creation\"\n",
    "\n",
    "test_files_touched()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------\n",
    "Materials licensed under [CC BY-NC-ND 4.0](https://creativecommons.org/licenses/by-nc-nd/4.0/) by the authors"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
